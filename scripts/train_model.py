import sys
import os
from pathlib import Path
import itertools  # DÃ¹ng cho Grid Search

# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import torch
import torch.nn.functional as F
from torch_geometric.loader import LinkNeighborLoader
from torch_geometric.nn import to_hetero
from torch_geometric.transforms import RandomLinkSplit
from sklearn.metrics import roc_auc_score
from tqdm import tqdm
import pickle
import argparse
import numpy as np

from config.settings import (
    GRAPH_PATH, MODEL_PATH, PYG_DATA_PATH, MAPPING_PATH,
    INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, EPOCHS, BATCH_SIZE, LEARNING_RATE
)
from infrastructure.repositories.graph_repo import PickleGraphRepository
from core.ai.gnn_architecture import GraphSAGE
from core.ai.data_processor import GraphDataProcessor
from infrastructure.repositories.feature_repo import PyGDataRepository


# --- 1. CHUáº¨N Bá»Š Dá»® LIá»†U ---
def get_or_prepare_data():
    """Táº£i hoáº·c táº¡o má»›i dá»¯ liá»‡u PyG."""
    feature_repo = PyGDataRepository(PYG_DATA_PATH, MAPPING_PATH)
    data, mapping = feature_repo.load_data()

    if data is None:
        print("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u PyG. Äang xá»­ lÃ½ tá»« NetworkX...")
        repo = PickleGraphRepository(GRAPH_PATH)
        G = repo.load_graph()
        if G is None:
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y Ä‘á»“ thá»‹ táº¡i {GRAPH_PATH}")

        processor = GraphDataProcessor()
        data, mapping = processor.process_graph_to_pyg(G)
        feature_repo.save_data(data, mapping)

    return data



# --- 2. CÃC HÃ€M HUáº¤N LUYá»†N & ÄÃNH GIÃ ---

def train_epoch(model, loader, optimizer, device, target_edge_type):
    """Cháº¡y 1 epoch huáº¥n luyá»‡n."""
    model.train()
    total_loss = 0
    total_examples = 0

    for batch in tqdm(loader, desc="Training", leave=False):
        batch = batch.to(device)
        optimizer.zero_grad()

        # Forward
        z_dict = model(batch.x_dict, batch.edge_index_dict)

        # Láº¥y nhÃ£n vÃ  index cáº¡nh cáº§n dá»± Ä‘oÃ¡n trong batch nÃ y
        edge_label_index = batch[target_edge_type].edge_label_index
        edge_label = batch[target_edge_type].edge_label

        # Decode (TÃ­nh Ä‘iá»ƒm)
        src_type, _, dst_type = target_edge_type
        z_src = z_dict[src_type][edge_label_index[0]]
        z_dst = z_dict[dst_type][edge_label_index[1]]
        out = (z_src * z_dst).sum(dim=-1)

        # Loss
        loss = F.binary_cross_entropy_with_logits(out, edge_label)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * edge_label.size(0)
        total_examples += edge_label.size(0)

    return total_loss / total_examples


@torch.no_grad()
def evaluate(model, loader, device, target_edge_type):
    """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh (tÃ­nh AUC)."""
    model.eval()
    preds = []
    ground_truths = []

    for batch in tqdm(loader, desc="Evaluating", leave=False):
        batch = batch.to(device)
        z_dict = model(batch.x_dict, batch.edge_index_dict)

        edge_label_index = batch[target_edge_type].edge_label_index
        edge_label = batch[target_edge_type].edge_label

        src_type, _, dst_type = target_edge_type
        z_src = z_dict[src_type][edge_label_index[0]]
        z_dst = z_dict[dst_type][edge_label_index[1]]

        out = (z_src * z_dst).sum(dim=-1).sigmoid()

        preds.append(out.cpu().numpy())
        ground_truths.append(edge_label.cpu().numpy())

    return roc_auc_score(np.concatenate(ground_truths), np.concatenate(preds))


# --- 3. CHIáº¾N LÆ¯á»¢C CHáº Y ---

def train_one_config(data, config, device, target_edge_type, final_mode=False):
    """
    Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i 1 bá»™ tham sá»‘ cá»¥ thá»ƒ.
    """
    # 1. KHá»I Táº O Tá»ª ÄIá»‚N Lá»ŠCH Sá»¬
    history = {
        "epoch": [],
        "loss": [],
        "val_auc": []  # CÃ³ thá»ƒ rá»—ng náº¿u lÃ  final_mode
    }
    hidden_dim = config['hidden_dim']
    lr = config['lr']
    epochs = config['epochs']

    print(f"\nâš™ï¸ Cáº¥u hÃ¬nh: Hidden={hidden_dim}, LR={lr}")

    # 1. Chia dá»¯ liá»‡u (náº¿u khÃ´ng pháº£i final)
    if final_mode:
        train_data = data
        val_loader = None
    else:
        # RandomLinkSplit Ä‘á»ƒ táº¡o táº­p Train/Val/Test
        transform = RandomLinkSplit(
            num_val=0.1,
            num_test=0.1,
            is_undirected=True,
            add_negative_train_samples=False,
            edge_types=[target_edge_type]
        )
        train_data, val_data, test_data = transform(data)

        # Loader cho táº­p Validation
        val_loader = LinkNeighborLoader(
            val_data,
            num_neighbors=[10, 5],
            edge_label_index=(target_edge_type, val_data[target_edge_type].edge_label_index),
            edge_label=val_data[target_edge_type].edge_label,
            batch_size=BATCH_SIZE,  # DÃ¹ng batch size lá»›n hÆ¡n cho eval cÅ©ng Ä‘Æ°á»£c
            shuffle=False
        )

    # 2. Loader cho táº­p Train
    # (Quan trá»ng: LinkNeighborLoader giÃºp khÃ´ng trÃ n RAM)
    train_loader = LinkNeighborLoader(
        train_data,
        num_neighbors=[10, 5],
        edge_label_index=(target_edge_type, train_data[target_edge_type].edge_index),
        neg_sampling_ratio=1.0,
        batch_size=BATCH_SIZE,
        shuffle=True
    )

    # 3. Model & Optimizer
    base_model = GraphSAGE(hidden_channels=hidden_dim, out_channels=OUTPUT_DIM, in_channels=INPUT_DIM)
    model = to_hetero(base_model, data.metadata(), aggr='sum').to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    best_val_auc = 0
    best_model_state = None

    # 4. Loop
    for epoch in range(1, epochs + 1):

        loss = train_epoch(model, train_loader, optimizer, device, target_edge_type)
        history["epoch"].append(epoch)
        history["loss"].append(float(loss))  # Ã‰p kiá»ƒu float Ä‘á»ƒ trÃ¡nh lá»—i JSON
        log_msg = f"Epoch {epoch:03d} | Loss: {loss:.4f}"

        # Náº¿u cÃ³ táº­p Val -> ÄÃ¡nh giÃ¡ & LÆ°u Best Model
        if val_loader:
            val_auc = evaluate(model, val_loader, device, target_edge_type)
            history["val_auc"].append(float(val_auc))

            log_msg += f" | Val AUC: {val_auc:.4f}"

            if val_auc > best_val_auc:
                best_val_auc = val_auc
                best_model_state = model.state_dict()

        print(log_msg)
    if final_mode:
        print(f"ğŸ’¾ Äang lÆ°u lá»‹ch sá»­ huáº¥n luyá»‡n vÃ o {TRAINING_HISTORY_PATH}...")
        try:
            with open(TRAINING_HISTORY_PATH, "w", encoding="utf-8") as f:
                json.dump(history, f, indent=4)
            print("âœ… ÄÃ£ lÆ°u lá»‹ch sá»­ thÃ nh cÃ´ng!")
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u lá»‹ch sá»­: {e}")
    # Náº¿u Final Mode (khÃ´ng cÃ³ Val), láº¥y state cuá»‘i cÃ¹ng
    if final_mode:
        best_model_state = model.state_dict()
        best_val_auc = 1.0  # (Giáº£ Ä‘á»‹nh)

    return best_val_auc, best_model_state


def run_grid_search():
    """Cháº¡y tÃ¬m kiáº¿m tham sá»‘ tá»‘i Æ°u."""
    data = get_or_prepare_data()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    target_edge_type = ('person','knows','person')

    # Äá»‹nh nghÄ©a lÆ°á»›i tham sá»‘
    param_grid = {
        'hidden_dim': [64, 128],
        'lr': [0.01,0.001],
        'epochs': [20]  # Test nhanh 20 epoch
    }

    keys, values = zip(*param_grid.items())
    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

    best_auc = 0
    best_params = None

    print(f"ğŸš€ Báº¯t Ä‘áº§u Grid Search trÃªn {len(combinations)} cáº¥u hÃ¬nh...")

    for config in combinations:
        auc, _ = train_one_config(data, config, device, target_edge_type)

        if auc > best_auc:
            best_auc = auc
            best_params = config
            print(f"ğŸ† Ká»· lá»¥c má»›i: AUC {auc:.4f} vá»›i {config}")

    print(f"\nâœ… Grid Search HoÃ n táº¥t. Tá»‘t nháº¥t: {best_params} (AUC: {best_auc:.4f})")

    # Sau khi tÃ¬m Ä‘Æ°á»£c, cháº¡y Final Training vá»›i tham sá»‘ tá»‘t nháº¥t
    print("\nğŸ‹ï¸ Báº¯t Ä‘áº§u Final Training (100 Epochs) vá»›i tham sá»‘ tá»‘t nháº¥t...")
    best_params['epochs'] = 100  # Train ká»¹
    _, final_state = train_one_config(data, best_params, device, target_edge_type, final_mode=True)

    # LÆ°u Model cuá»‘i cÃ¹ng
    print(f"ğŸ’¾ Äang lÆ°u Final Model vÃ o {MODEL_PATH}...")
    torch.save(final_state, MODEL_PATH)


if __name__ == "__main__":
    run_grid_search()